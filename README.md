# ğŸš• NYC Taxi Data Lakehouse

![Data Engineering](https://img.shields.io/badge/Data%20Engineering-Senior-blue)
![GCP](https://img.shields.io/badge/Cloud-GCP-green)
![Terraform](https://img.shields.io/badge/IaC-Terraform-purple)
![Python](https://img.shields.io/badge/Language-Python%203.9+-yellow)
![Airflow](https://img.shields.io/badge/Orchestration-Airflow-red)

Este proyecto implementa una arquitectura de **Data Lakehouse** profesional para el procesamiento de datos masivos de los taxis de Nueva York (NYC Taxi & Limousine Commission). El objetivo es demostrar un flujo end-to-end robusto, escalable y automatizado, siguiendo las mejores prÃ¡cticas de la industria.

## ğŸ—ï¸ Arquitectura y TecnologÃ­as

El sistema estÃ¡ diseÃ±ado bajo el paradigma de **Infraestructura como CÃ³digo (IaC)** y procesamiento eficiente en memoria:

*   **Cloud Provider**: Google Cloud Platform (GCP).
*   **Infraestructura**: Terraform (GCS Buckets, BigQuery Datasets).
*   **Procesamiento**: Python 3.10+ con **Polars** (alto rendimiento y bajo consumo de memoria).
*   **GestiÃ³n de Dependencias**: `uv` (el gestor de paquetes mÃ¡s rÃ¡pido del ecosistema Python).
*   **ContenerizaciÃ³n**: Docker para portabilidad total.
*   **OrquestaciÃ³n**: Apache Airflow (vÃ­a Docker Compose).
*   **Almacenamiento**: Data Lake (GCS) + Data Warehouse (BigQuery).

## ğŸ“‚ Estructura del Proyecto

```text
.
â”œâ”€â”€ dags/                   # Definiciones de flujos en Airflow
â”œâ”€â”€ infrastructure/         # CÃ³digo de Terraform para la nube
â”‚   â””â”€â”€ terraform/          # DefiniciÃ³n de recursos GCP
â”œâ”€â”€ src/                    # CÃ³digo fuente de la lÃ³gica de negocio
â”‚   â””â”€â”€ ingestion/          # Scripts de ingesta y transformaciÃ³n inicial
â”œâ”€â”€ gcp_credentials/        # ğŸ”’ Directorio para llaves JSON (ignorado en Git)
â”œâ”€â”€ Dockerfile              # Receta para el contenedor de ingesta
â”œâ”€â”€ docker-compose.yml      # ConfiguraciÃ³n de la plataforma Airflow
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n de dependencias (uv)
â””â”€â”€ tutorial.md             # GuÃ­a detallada paso a paso
```

## ğŸš€ Puesta en Marcha

Como Data Engineer Senior, he diseÃ±ado este proceso para que sea reproducible y seguro.

### 1. PreparaciÃ³n de Credenciales
1. Crea un proyecto en GCP.
2. Habilita las APIs de Storage, BigQuery y Compute Engine.
3. Crea una Service Account con rol de `Owner` (para desarrollo) y descarga la llave JSON.
4. Guarda la llave en `gcp_credentials/terraform-key.json`.

### 2. Despliegue de Infraestructura (Terraform)
```bash
cd infrastructure/terraform
terraform init
terraform plan
terraform apply
```
*Esto crearÃ¡ automÃ¡ticamente tu Bucket en GCS y el Dataset en BigQuery.*

### 3. ConfiguraciÃ³n del Entorno Local
Usamos `uv` para una gestiÃ³n de paquetes ultra-rÃ¡pida:
```bash
uv venv
source .venv/bin/activate
uv sync
```

### 4. EjecuciÃ³n de la Ingesta (Docker)
Puedes correr el proceso de ingesta de forma aislada:
```bash
# Construir la imagen
docker build -t nyc-taxi-ingestor:v1 .

# Ejecutar para un mes especÃ­fico
docker run --rm \
  -v $(pwd)/gcp_credentials:/app/gcp_credentials \
  -e GOOGLE_APPLICATION_CREDENTIALS=/app/gcp_credentials/terraform-key.json \
  -e GCS_BUCKET_NAME="tu-bucket-name" \
  nyc-taxi-ingestor:v1 --year 2024 --month 1
```

### 5. OrquestaciÃ³n con Airflow
Para levantar la plataforma completa de orquestaciÃ³n:
```bash
docker compose up -d
```
Accede a la interfaz en `http://localhost:8080` (User/Pass: `admin`/`admin`).

## ğŸ› ï¸ Mejores PrÃ¡cticas Implementadas

*   **ProgramaciÃ³n Orientada a Objetos (POO)**: El ingestor estÃ¡ encapsulado en clases modulares y testeables.
*   **Particionamiento Hive**: Los datos se almacenan en GCS siguiendo el patrÃ³n `year=YYYY/month=MM/` para optimizar costos y velocidad en BigQuery.
*   **Seguridad**: Uso estricto de `.gitignore` para proteger secretos y variables de entorno.
*   **Logging y Observabilidad**: ImplementaciÃ³n de logs estructurados para facilitar el debugging en producciÃ³n.
*   **Docker out of Docker**: Airflow configurado para lanzar tareas en contenedores hermanos, manteniendo el orquestador limpio.

---
*Desarrollado con â¤ï¸ por un Data Engineer Senior para la comunidad.*
